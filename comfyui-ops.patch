diff --git a/comfy/model_base.py b/comfy/model_base.py
index 66e52864..4bb69bc0 100644
--- a/comfy/model_base.py
+++ b/comfy/model_base.py
@@ -203,7 +203,11 @@ class BaseModel(torch.nn.Module):
         if "latent_shapes" in extra_conds:
             xc = utils.unpack_latents(xc, extra_conds.pop("latent_shapes"))
 
-        model_output = self.diffusion_model(xc, t, context=context, control=control, transformer_options=transformer_options, **extra_conds)
+        comfy.ops.set_nfp4_log_enabled(True)
+        try:
+            model_output = self.diffusion_model(xc, t, context=context, control=control, transformer_options=transformer_options, **extra_conds)
+        finally:
+            comfy.ops.set_nfp4_log_enabled(False)
         if len(model_output) > 1 and not torch.is_tensor(model_output):
             model_output, _ = utils.pack_latents(model_output)
 
diff --git a/comfy/ops.py b/comfy/ops.py
index e406ba7e..78eabb9b 100644
--- a/comfy/ops.py
+++ b/comfy/ops.py
@@ -18,9 +18,21 @@
 
 import torch
 import logging
+import os
 import comfy.model_management
 from comfy.cli_args import args, PerformanceFeature
 import comfy.float
+
+_nfp4_log_enabled = False
+
+
+def set_nfp4_log_enabled(enabled: bool) -> None:
+    global _nfp4_log_enabled
+    _nfp4_log_enabled = bool(enabled)
+
+
+def get_nfp4_log_enabled() -> bool:
+    return _nfp4_log_enabled
 import comfy.rmsnorm
 import json
 
@@ -545,6 +557,7 @@ def mixed_precision_ops(quant_config={}, compute_dtype=torch.bfloat16, full_prec
 
                 device = self.factory_kwargs["device"]
                 layer_name = prefix.rstrip('.')
+                self._quant_layer_name = layer_name
                 weight_key = f"{prefix}weight"
                 weight = state_dict.pop(weight_key, None)
                 if weight is None:
@@ -667,14 +680,54 @@ def mixed_precision_ops(quant_config={}, compute_dtype=torch.bfloat16, full_prec
                 input_shape = input.shape
                 reshaped_3d = False
 
+                # Reshape 3D tensors to 2D for logging/quantization
+                input_reshaped = input.reshape(-1, input_shape[2]) if input.ndim == 3 else input
+
+                if input_reshaped.ndim == 2:
+                    scale = getattr(self, 'input_scale', None)
+                    if scale is not None:
+                        scale = comfy.model_management.cast_to_device(scale, input.device, None)
+                    log_path = os.getenv("COMFY_NFP4_LOG_INPUT_SCALE_PATH", "")
+                    log_always = os.getenv("COMFY_NFP4_LOG_ALWAYS", "")
+                    if log_path and (log_always or get_nfp4_log_enabled()):
+                        try:
+                            layer = getattr(self, "_quant_layer_name", "<unknown>")
+                            fmt = getattr(self, "quant_format", "unknown")
+                            mode = "provided" if scale is not None else "dynamic"
+                            abs_input = input_reshaped.detach().abs()
+                            if abs_input.dim() > 1:
+                                reduce_dims = tuple(range(abs_input.dim() - 1))
+                                per_channel = abs_input.amax(dim=reduce_dims)
+                            else:
+                                per_channel = abs_input
+                            if scale is None:
+                                scale_val = None
+                            else:
+                                try:
+                                    scale_val = float(scale.item())
+                                except Exception:
+                                    scale_val = float(scale.mean().item())
+
+                            record = {
+                                "format": fmt,
+                                "mode": mode,
+                                "layer": layer,
+                                "shape": tuple(input_reshaped.shape),
+                                "global_amax": float(abs_input.max().item()),
+                                "per_channel_amax": per_channel.to(dtype=torch.float32, device="cpu"),
+                                "input_scale": scale_val,
+                                "channel_axis": -1,
+                            }
+                            with open(log_path, "ab") as f:
+                                torch.save(record, f)
+                        except Exception:
+                            pass
+
                 if (getattr(self, 'layout_type', None) is not None and
                     not isinstance(input, QuantizedTensor) and not self._full_precision_mm and
                     not getattr(self, 'comfy_force_cast_weights', False) and
                     len(self.weight_function) == 0 and len(self.bias_function) == 0):
 
-                    # Reshape 3D tensors to 2D for quantization (needed for NVFP4 and others)
-                    input_reshaped = input.reshape(-1, input_shape[2]) if input.ndim == 3 else input
-
                     # Fall back to non-quantized for non-2D tensors
                     if input_reshaped.ndim == 2:
                         reshaped_3d = input.ndim == 3
