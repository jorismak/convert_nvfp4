diff --git a/comfy/ops.py b/comfy/ops.py
index e406ba7e..966a0fb1 100644
--- a/comfy/ops.py
+++ b/comfy/ops.py
@@ -18,6 +18,7 @@
 
 import torch
 import logging
+import os
 import comfy.model_management
 from comfy.cli_args import args, PerformanceFeature
 import comfy.float
@@ -545,6 +546,7 @@ def mixed_precision_ops(quant_config={}, compute_dtype=torch.bfloat16, full_prec
 
                 device = self.factory_kwargs["device"]
                 layer_name = prefix.rstrip('.')
+                self._quant_layer_name = layer_name
                 weight_key = f"{prefix}weight"
                 weight = state_dict.pop(weight_key, None)
                 if weight is None:
@@ -682,6 +684,40 @@ def mixed_precision_ops(quant_config={}, compute_dtype=torch.bfloat16, full_prec
                         scale = getattr(self, 'input_scale', None)
                         if scale is not None:
                             scale = comfy.model_management.cast_to_device(scale, input.device, None)
+                        log_path = os.getenv("COMFY_NFP4_LOG_INPUT_SCALE_PATH", "")
+                        if log_path and getattr(self, "quant_format", None) in {"nvfp4", "float8_e4m3fn", "float8_e5m2"}:
+                            try:
+                                layer = getattr(self, "_quant_layer_name", "<unknown>")
+                                fmt = getattr(self, "quant_format", "unknown")
+                                mode = "provided" if scale is not None else "dynamic"
+                                abs_input = input_reshaped.detach().abs()
+                                if abs_input.dim() > 1:
+                                    reduce_dims = tuple(range(abs_input.dim() - 1))
+                                    per_channel = abs_input.amax(dim=reduce_dims)
+                                else:
+                                    per_channel = abs_input
+                                if scale is None:
+                                    scale_val = None
+                                else:
+                                    try:
+                                        scale_val = float(scale.item())
+                                    except Exception:
+                                        scale_val = float(scale.mean().item())
+
+                                record = {
+                                    "format": fmt,
+                                    "mode": mode,
+                                    "layer": layer,
+                                    "shape": tuple(input_reshaped.shape),
+                                    "global_amax": float(abs_input.max().item()),
+                                    "per_channel_amax": per_channel.to(dtype=torch.float32, device="cpu"),
+                                    "input_scale": scale_val,
+                                    "channel_axis": -1,
+                                }
+                                with open(log_path, "ab") as f:
+                                    torch.save(record, f)
+                            except Exception:
+                                pass
                         input = QuantizedTensor.from_float(input_reshaped, self.layout_type, scale=scale)
 
                 output = self.forward_comfy_cast_weights(input)
